---
title: 'More thoughts on the state of AI'
date: '2023-03-31T11:15:00.000Z'
description: 'So, the cat is out of the bag and we learn more and more. But still we do not know where everything will lead to.'
devTo: 'https://dev.to/syeo66/thoughts-on-the-current-state-of-ai-322f'
---

I recently wrote an article with my thoughts on the state of AI. Little did I know about the flurry of developments we would face in only a few days. We are now at a point where high profile people are asking to pause and think. And I am sure we should pause and think. Does this mean we should stop the development? It's not even a question: The cat is out of the bag - there is no stopping now. What we should do is increase the efforts in the fields of AI safety, ethics, social development, and the definition of human work... by a lot.

There were more than enough examples in the past where those voices asking for more consideration were silenced in the name of profit. We can't do that anymore. The price is simply to high. Do I have the answers? No, nobody has. We just don't know what we are and will be dealing with.

Anyways, here are some thoughts keeping my brain busy lately.

## Noise-to-signal ratio

AIs help us to create content at a way faster pace. Even without any training you can put out texts, images and other things which a few years ago would have needed quite some skills. Now those things are available with a click of a button. Sure, someone might argue skills are still important and being able to build on the AIs output will lead to better results from experts. Even if this is really true (I will discuss this a bit more in depth below) the big problem will be to actually find the 'diamonds' within the noise. Not only is there more content burrying the great content, the noise is actually also louder. In many cases it actually takes an expert to be even able to discerne the good from the not so good stuff.

Just recently Github Copilot X was presented and on their site it was stated that 46% of code is already created by Copilot (I am not really sure about that number, but let's just run with it). The same will probably happen with the flood of generated images and texts. Bots just creating websites with the help of GPT-4 for SEO reasons are probably already at work. If we extrapolate this development it's easy to see that in a not too far future we will basically train the models with 99% AI generated content. This might lead to whole bunch of problems down the line like even further bias amplification and similar things.

## Killing creativity and knowledge

Too often we hear the question "should I even learn to..." especially when it comes to start learning to code. The answer is "yes" most of the time. But if we think about artists creating especially digital art, music or texts. Why should they spend thousands of hours honing their skills if anyone can create something with a short prompt which most of the people out there wouldn't be able to distinguish from your work. What does a skilled artist think about some models just taking your work and create thousands of images in a style you developed with years of hard work?

I think this might lead to a decline of artistic and creativ work. There is simply no incentive to keep on doing the work anymore. Sure, one might argue you should do it for fun and not for money. But this has been the argument which allowed the exploitation of artists, musicians and many other creative workers for decades.

As we have seen the flood of generated content will drown the work of skilled people, AIs will be trained by generated content and artist have less incentives to hone their skills. So, we will see a slow decline of creativity and knowledge.

## To AGI or not to AGI

### Human level AI

### Non-human AGI
